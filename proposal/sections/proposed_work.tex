In light of the issues with Reddit, it is valuable to determine the reliability
of Redditors automatically. We plan to do this by creating a Reliability Score,
ranging beetween $-1.0$ and $1.0$, in which a more positive number denotes a
user who is more reliable, and a negative score denotes a user who is less
reliable. Furthermore, we hope to show that based on indicators used to
calculate this score over time, that we can anticipate the trend of a Redditor's
reliability. This has implications in creating reliable users by predicting
their trajectory of behavior. One could take this trajectory, compare it to a
more `desirable' trajectory, and perhaps even nudge Redditors towards a more
Reliable trajectory.

The following sections discuss some technical challenges we anticipate, and our
plans to overcome them.

\subsection{Creating A Reliability Score}
\label{sub:creating_a_reliability_score}

In coming up with a metric for determining reliability of a user, there are
certain traits of a reddit user that should be addresssed.

`Karma', reddit's crowd-sourced measure of whether or not a user's submitted
content is ``good'', allows other users to rapidly identify whether or not a
user tends to post interesting/good content relative to how the ``hivemind''
feels (based on a user's net post/comment karma). Karma, in itself, however, is
not a proper measurement for how reliable a reddit user is, as one could gain
karma for posting content that the hivemind simply approves of - puns, cat
pictures, references to past popular reddit threads - and not necessarily for
content that proves to be important relative to the ``real world''.

Posting in trusted subreddits, however, is a step forward in turning karma from
a measurement of approval by the community into a measurement of reliability as
given by the hivemind. By removing karma given by subreddits which have a dearth
of ``serious'' content (such as \texttt{r/funny}) in favor of those with a
wealth of serious content (such as \texttt{r/news}), we skew the existing
measurement of karma into one that is based upon trust from redditor to
redditor - that is, instead of being a measurement of how much redditors approve
of a specific piece of submitted content, karma now becomes a measurement of how
trustworthy that specific piece of content is - and in aggregate, becomes a
measurement of how trustworthy/reliable that user is.

It is also important to take into account the sharing of content from reputable,
reliable sources. Given the nature of reddit, one could easily share serious
content from reputable sources like the New York Times on subreddits that may
not necessarily be serious, like on \texttt{r/nottheonion}, where users share
links to articles which sound like they could be written by and published in the
Onion but are, in fact, serious articles. In cases like this, it is readily
evident that the actual subreddit is less important, in favor of the actual
content itself.

There are also numerous other metrics that can serve as a proxy for reliability,
such as account duration and the user's choice of subreddits to post in. Account
duration could be used as an identifier to determine if an account is being used
as a ``throwaway'', or an account that is merely being used to create
controversy/share opinions that might not be popular without linking it to one's
primary username. Similarly, a user's choice of subreddits could be used as a
proxy to determine whether or not a user is reliable simply by seeing what their
interests are. For example, given two users, one frequenting \texttt{r/funny}, a
subreddit where users post funny content versus one who frequents
\texttt{r/news}, where users post U.S. news, odds are that the second user will
be posting more reliable, serious content than the first user.

In an effort to reap all the benefits that inherently exist within data being
generated by redditors and gathered by reddit, we propose this notion of a
reliability score, a aggregate score generated by the fusion of all these
different factors into a number which is quickly able to identify whether or not
a user is reliable.

% subsubsection creating_a_reliability_score (end)

\subsection{Gathering Usernames}
\label{sub:gathering_usernames}

Reddit does not have an API for gathering or searching for usernames. It does
however, allow one to see popular posts on particular Subreddits, or in general,
the front page. We plan to mine usernames by looking at popular posts and
comments on those posts, and logging the usernames associated with those
activities. This list of usernames can then be plugged into our reliability
score calculations, and used to train our classifiers for behavior prediciton.

% subsubsection gathering_usernames (end)

\subsection{Verification}
\label{sub:verification}

Verification of reliability is tricky. Though it is labour intensive, we will
have to select a control group of users, view their history manually, decide if
they are `reliable' or not, and then compare that to the score our classifier
gives.

Verification of behavior prediction is less tricky. We can simply use our models
to predict the future behavior of old users, and then compare that to their
actual trajectory.

% subsubsection verification (end)

